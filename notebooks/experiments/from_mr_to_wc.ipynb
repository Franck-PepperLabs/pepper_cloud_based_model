{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MapReduce** et **WordCount**\n",
    "\n",
    "Notebook juste pour refaire les exemple du cours sur Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def wordCount(text):\n",
    "    counts = defaultdict(int)\n",
    "    for word in text.split():\n",
    "        counts[word.lower()] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = {\"./lot1.txt\": \"jour lève notre grisaille\"}\n",
    "D2 = {\"./lot2.txt\": \"trottoir notre ruelle notre tour\"}\n",
    "D3 = {\"./lot3.txt\": \"jour lève notre envie vous\"}\n",
    "D4 = {\"./lot4.txt\": \"faire comprendre tous notre tour\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map(key, value):\n",
    "    return key, [(word, 1) for word in value.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(key, values):\n",
    "    result = sum(values)\n",
    "    return key, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"lot1\": \"jour lève notre grisaille\",\n",
    "    \"lot2\": \"trottoir notre ruelle notre tour\",\n",
    "    \"lot3\": \"jour lève notre envie vous\",\n",
    "    \"lot4\": \"faire comprendre tous notre tour\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lot1': [('jour', 1), ('lève', 1), ('notre', 1), ('grisaille', 1)],\n",
       " 'lot2': [('trottoir', 1),\n",
       "  ('notre', 1),\n",
       "  ('ruelle', 1),\n",
       "  ('notre', 1),\n",
       "  ('tour', 1)],\n",
       " 'lot3': [('jour', 1), ('lève', 1), ('notre', 1), ('envie', 1), ('vous', 1)],\n",
       " 'lot4': [('faire', 1),\n",
       "  ('comprendre', 1),\n",
       "  ('tous', 1),\n",
       "  ('notre', 1),\n",
       "  ('tour', 1)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapped = {\n",
    "    key: _map(key, value)[1]\n",
    "    for key, value in corpus.items()\n",
    "}\n",
    "display(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jour': 2,\n",
       " 'lève': 2,\n",
       " 'notre': 5,\n",
       " 'grisaille': 1,\n",
       " 'trottoir': 1,\n",
       " 'ruelle': 1,\n",
       " 'tour': 2,\n",
       " 'envie': 1,\n",
       " 'vous': 1,\n",
       " 'faire': 1,\n",
       " 'comprendre': 1,\n",
       " 'tous': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _shuffle_sort(mapped):\n",
    "    shuffled = {}\n",
    "    for pair_list in mapped.values():\n",
    "        for k, v in pair_list:\n",
    "            if k in shuffled:\n",
    "                shuffled[k] += v\n",
    "            else:\n",
    "                shuffled[k] = v\n",
    "    return shuffled\n",
    "_shuffle_sort(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISCOURS DE LA METHODE',\n",
       " '',\n",
       " 'POUR BIEN CONDUIRE SA RAISON,',\n",
       " '',\n",
       " 'ET CHERCHER LA VERITE DANS LES SCIENCES',\n",
       " '',\n",
       " '',\n",
       " \"Si ce discours semble trop long pour �tre lu en une fois, on le pourra distinguer en six parties. Et, en la premi�re, on trouvera diverses consid�rations touchant les sciences. En la seconde, les principales r�gles de la m�thode que l'auteur a cherch�e. En la troisi�me, quelques unes de celles de la morale qu'il a tir�e de cette m�thode. En la quatri�me, les raisons par lesquelles il prouve l'existence de Dieu et de l'�me humaine, qui sont les fondements de sa m�taphysique. En la cinqui�me, l'ordre des questions de physique qu'il a cherch�es, et particuli�rement l'explication des mouvements du coeur et de quelques autres difficult�s qui appartiennent � la m�decine; puis aussi la diff�rence qui est entre notre �me et celle des b�tes. Et en la derni�re, quelles choses il croit �tre requises pour aller plus avant en la recherche de la nature qu'il n'a �t�, et quelles raisons l'ont fait �crire.\",\n",
       " '',\n",
       " '']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['DISCOURS',\n",
       " 'DE',\n",
       " 'LA',\n",
       " 'METHODE',\n",
       " '',\n",
       " 'POUR',\n",
       " 'BIEN',\n",
       " 'CONDUIRE',\n",
       " 'SA',\n",
       " 'RAISON,']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('DISCOURS', 1),\n",
       " ('DE', 1),\n",
       " ('LA', 1),\n",
       " ('METHODE', 1),\n",
       " ('', 1),\n",
       " ('POUR', 1),\n",
       " ('BIEN', 1),\n",
       " ('CONDUIRE', 1),\n",
       " ('SA', 1),\n",
       " ('RAISON,', 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA 2\n",
      "METHODE 1\n",
      " 92\n",
      "POUR 1\n",
      "BIEN 1\n",
      "CONDUIRE 1\n",
      "ET 1\n",
      "VERITE 1\n",
      "LES 1\n",
      "ce 159\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Instantiation d'un SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "# Lecture d'un fichier texte : le fichier est décomposé en lignes.\n",
    "lines = sc.textFile(\"Discours de la méthode.txt\") \n",
    "display(lines.take(10))\n",
    "\n",
    "# Décomposition de chaque ligne en mots (et aplatissement)\n",
    "tokenized_lines = lines.flatMap(lambda line: line.split(' '))\n",
    "display(tokenized_lines.take(10))\n",
    "\n",
    "# Chacun des mots est transformé en une clé-valeur\n",
    "mapped_lines = tokenized_lines.map(lambda word: (word, 1))\n",
    "display(mapped_lines.take(10))\n",
    "\n",
    "# Les valeurs associées à chaque clé sont sommées\n",
    "word_counts = mapped_lines.reduceByKey(lambda count1, count2: count1 + count2)\n",
    "\n",
    "# This word_counts is a RDD\n",
    "display(word_counts)\n",
    "#word_counts.foreachPartition(lambda p: print(list(p)[:10]))\n",
    "\n",
    "# Le résultat est récupéré => lazy eval\n",
    "word_counts = word_counts.collect()\n",
    "\n",
    "# Chaque paire (clé, valeur) est affichée\n",
    "for (word, count) in word_counts[:10]:\n",
    "    print(word, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
